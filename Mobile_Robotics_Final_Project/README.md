# Dynamic ORB based In-MSCKF
**Authors:** [Gitesh Sambhaji Gunjal](https://github.com/giteshgunjal), [Ming-Yang Lo](https://github.com/MingYangLo), [Ruichang Chen](https://github.com/chenrc98), [Chengyu Shi](https://github.com/chengyus1012)

This is the ccode repostitory for Team 2 of the Winter 2022 version of Mocile Robotics. 
This project made three major changes to the [MSCKF_VIO](https://github.com/KumarRobotics/msckf_vio). First, the feature extractor changed to ORB. Second, implemented [YOLACT](https://github.com/dbolya/yolact) with [pretrained weights](*link) for object instance segmentation to create masks of predicted dynamic objects. Last, modified the propagation, augmentation, and correction steps of [MSCKF_VIO](https://github.com/KumarRobotics/msckf_vio)from EKF to RightIn-EKF.

## License

Dynamic ORB based In-MSCKF is based on [MSCKF_VIO](https://github.com/KumarRobotics/msckf_vio) and [YOLACT](https://github.com/dbolya/yolact), and as such are released under a [Penn Software License](https://github.com/KumarRobotics/msckf_vio/blob/master/LICENSE.txt) and [MIT License](https://github.com/dbolya/yolact/blob/master/LICENSE) respectively.

## Dependencies
This software is tested on Ubuntu 16.04 with ROS Kinetic & Ubuntu 18.04 with Melodic.

- For MSCKF_VIO
    Dependencies are standard including `Eigen`, `OpenCV`, and `Boost`. One special requirement is `suitesparse`, which can be installed through,
    ```
   sudo apt-get install libsuitesparse-dev
    ```
- For YOLACT
    TODO


## Compiling and Installation
YOLACT -->> TODO


If compile with Ubuntu 18.04, should include the [random_numbers folder](https://github.com/ros-planning/random_numbers) which is also included [in this repository](https://github.com/MingYangLo/Mobile_Robotics/tree/main/Mobile_Robotics_Final_Project/random_numbers) for a successful compilation.

The software is a standard catkin package. Make sure the package is on ROS_PACKAGE_PATH after cloning the package to your workspace. And the normal procedure for compiling a catkin package should work.
```
cd your_work_space
catkin_make --pkg msckf_vio --cmake-args -DCMAKE_BUILD_TYPE=Release
```

## Calibration
An accurate calibration is crucial for successfully running the software. To get the best performance of the software, the stereo cameras and IMU should be hardware synchronized. Note that for the stereo calibration, which includes the camera intrinsics, distortion, and extrinsics between the two cameras, you have to use a calibration software. **Manually setting these parameters will not be accurate enough.** [Kalibr](https://github.com/ethz-asl/kalibr) can be used for the stereo calibration and also to get the transformation between the stereo cameras and IMU. The yaml file generated by Kalibr can be directly used in this software. See calibration files in the `config` folder for details. The two calibration files in the `config` folder should work directly with the EuRoC and KAIST (only set for urban28, might need a further look if running on others) datasets. The convention of the calibration file is as follows:

`camx/T_cam_imu`: takes a vector from the IMU frame to the camx frame.
`cam1/T_cn_cnm1`: takes a vector from the cam0 frame to the cam1 frame.

The filter uses the first 200 IMU messages to initialize the gyro bias, acc bias, and initial orientation. Therefore, the robot is required to start from a stationary state in order to initialize the VIO successfully.


## EuRoC and KAIST dataset example usage

First obtain either the [EuRoC](https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets) or the [KAIST Urban](https://sites.google.com/view/complex-urban-dataset/download-lidar-stereo?authuser=0) dataset.

Recommended EuRoC ROS Bags:
- [Vicon Room 1 01](http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_01_easy/V1_01_easy.bag)
- [Vicon Room 1 02](http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_02_easy/V1_02_easy.bag)

Once the `msckf_vio` is built and sourced (via `source <path to catkin_ws>/devel/setup.bash`), there are launch files prepared for the [EuRoC](https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets) and [KAIST Urban](https://sites.google.com/view/complex-urban-dataset/download-lidar-stereo?authuser=0) dataset named `msckf_vio_euroc.launch` and `msckf_vio_kaist.launch` respectively. Each launch files instantiates two ROS nodes:

* `image_processor` processes stereo images to detect and track features
* `vio` obtains feature measurements from the `image_processor` and tightly fuses them with the IMU messages to estimate pose.

These launch files can be executed via

```
roslaunch msckf_vio msckf_vio_euroc.launch
```
or

```
roslaunch msckf_vio msckf_vio_kaist.launch
```

Once the nodes are running you need to run the dataset rosbags (in a different terminal), for example:

```
rosbag play V1_01_easy.bag
```

As mentioned in the previous section, **The robot is required to start from a stationary state in order to initialize the VIO successfully.**

To visualize the pose and feature estimates you can use the provided rviz configurations found in `msckf_vio/rviz` folder (EuRoC: `rviz_euroc_config.rviz`, Fast dataset: `rviz_kaist_config.rviz`).

Note that KAIST dataset might not work that well due to few mathematical issues.


## ROS Nodes

### `image_processor` node

**Subscribed Topics**

`imu` (`sensor_msgs/Imu`)

IMU messages is used for compensating rotation in feature tracking, and 2-point RANSAC.

`cam[x]_image` (`sensor_msgs/Image`)

Synchronized stereo images.

**Published Topics**

`features` (`msckf_vio/CameraMeasurement`)

Records the feature measurements on the current stereo image pair.

`tracking_info` (`msckf_vio/TrackingInfo`)

Records the feature tracking status for debugging purpose.

`debug_stereo_img` (`sensor_msgs::Image`)

Draw current features on the stereo images for debugging purpose. Note that this debugging image is only generated upon subscription.

### `vio` node

**Subscribed Topics**

`imu` (`sensor_msgs/Imu`)

IMU measurements.

`features` (`msckf_vio/CameraMeasurement`)

Stereo feature measurements from the `image_processor` node.

**Published Topics**

`odom` (`nav_msgs/Odometry`)

Odometry of the IMU frame including a proper covariance.

`feature_point_cloud` (`sensor_msgs/PointCloud2`)

Shows current features in the map which is used for estimation.


